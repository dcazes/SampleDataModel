#######################################################################################################
## Project Name:    TempPulseNet                                                                     ##
## Project          Description: RCNN Aimed at Predicting Pulsatile Signal Present Within BOLD fMRI  ##
## Author:          Daniel Cazes                                                                     ##
## Date Created:    July 26, 2019                                                                    ##
## Date of Latest   Revision: Today                                                                  ##
#######################################################################################################

###################
# Python Packages #
###################
from keras.layers import ConvLSTM2D, BatchNormalization, LeakyReLU, Dropout
#from sklearn.preprocessing import normalize, minmax_scale
from sklearn.model_selection import train_test_split
from keras.models import Sequential
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sns
import nibabel as nib
import numpy as np
import csv
import gc
import os

sns.set()
#########################
# Data Import Variables #
#########################
#Samples per Patient
numSam = 195

#Data Dimensions
rows = 80
cols = 80
depth = 28

#Data Dimension Cut
rowRed = 10
colRed = 8

rowCut = rows - (rowRed * 2)
colCut = cols - (colRed * 2)

############################
# Model Training Variables #
############################

#Number of Epochs
nEpoch = 200

#Validation Set Size
valSize = 0.2

#Optimizer
opt = tf.train.AdamOptimizer(learning_rate=0.001)

#Loss Function
lossFunc = 'MSE'

############################
# Graph and File Variables #
############################

#Font
#font_prop = fm.FontProperties(size=16)

#Predictions Vs Actual Name
figName = "ConvLSTM"

#Output Folder
path = "TempPulseNet/"

#Run Details (Explain how to compare this Error to other runs' error)
dets = "SliceData"

##################
# Importing Data #
##################
def ImportData ():

    #print(numList[i])
    #sns.heatmap(inDataCut[i, :, :, 0, 20])
    #plt.show()

    #Define List of RISE subject numbers
    numList = ["2078", "2080", "2081", "2082", "2083", "2084", "2092", "2093", "2094", "2102"]
    #"2078", "2080", "2081", "2082", "2083", "2084", "2092", "2093", "2094", "2102"

    numPat = len(numList)

    #Create Arrays
    inData = np.zeros((numPat, rowCut, colCut, depth, numSam))
    outData = np.zeros((numPat, rowCut, colCut, depth))

    for i in range (len(numList)):
        #Assign Path To NII Files
        inDataFull = np.zeros((rows, cols, depth, numSam))
        outDataFull = np.zeros((rows, cols, depth))

        #Load Data into Img Variable
        inDataFull = nib.nifti1.load('./RISE2/Pulsatility_Data_Processed_SAtwi/RISE%s/RISE%s_echo2_bet.nii' %(numList[i], numList[i])).get_fdata()
        outDataFull = nib.nifti1.load('./RISE2/Pulsatility_Data_Processed_SAtwi/RISE%s/echo2_100vol_cardiac_RISE%s_RMS.nii' %(numList[i], numList[i])).get_fdata()
        
        #Cut some edge voxels
        inData[i, :, :, :, :] = inDataFull[rowRed:-rowRed, colRed:-colRed, :, :]
        outData[i, :, :, :] = outDataFull[rowRed:-rowRed, colRed:-colRed, :]
        
        del inDataFull, outDataFull
        gc.collect()

    #Move time dimension to correct spot
    inData = np.moveaxis(inData, 4, 1)
    print ("1")
    print (inData.shape)
    print (outData.shape)

    Flatten and MinMax Scale Data
    flatIn = inData.flatten()
    flatOut = outData.flatten()
    flatIn = minmax_scale(flatIn)
    flatOut = minmax_scale(flatOut)
    inData = flatIn.reshape(inData.shape)
    outData = flatOut.reshape(outData.shape)
    
    #define reshaping array
    reshaped_volumes = np.zeros((numPat * depth, numSam, rowCut, colCut, 1))
    reshaped_output = np.zeros((numPat * depth, rowCut, colCut, 1))

    for j in range(numPat):
        for i in range (depth):
            reshaped_volumes[((j*depth) + i), :, :, :, 0] = inData[j, :, :, :, i]
            reshaped_output[((j*depth) + i), :, :, 0] = outData[j, :, :, i]
    print ("2")
    print (reshaped_volumes.shape)
    print (reshaped_output.shape)
            
    #del inData, outData
    gc.collect()
    return reshaped_volumes, reshaped_output

#########
# Model #
#########

def TPNet(fMRI, pMap):

    model = Sequential()

    model.add (BatchNormalization(input_shape=(numSam, rowCut, colCut, 1), axis = -1))
    model.add(ConvLSTM2D(3, kernel_size = (11, 11), padding='same', return_sequences=True))
    model.add(LeakyReLU(0.0))
    model.add (BatchNormalization(axis = -1))
    model.add(ConvLSTM2D(1, kernel_size = (11, 11), padding='same', return_sequences=False))
    model.add(LeakyReLU(0.0))

    model.compile(optimizer = opt, loss = lossFunc)

    #Split data into training and validation set and fit
    x_train, x_val, y_train, y_val = train_test_split(fMRI, pMap, test_size = 0.1)
    history = model.fit(x_train, y_train, epochs= nEpoch, validation_data=(x_val, y_val))

    del x_train, y_train
    gc.collect()

    return model, history, x_val, y_val

######################################
#  Error Calculation / Write to File #
######################################

def error(Y_test, pred):

    #Disparity Error for input signal middle voxel
    dispHR = 100 * ((Y_test - pred)/(Y_test + pred))

    #File Name
    dispFile = "EmpiricalSliceError.csv"

    #flatten data for writing to file
    histDispHR = dispHR.flatten()

    #Write to file
    with open(path + dispFile, 'a') as csvFile:
        for i in range (len(histDispHR)):
            row = [histDispHR[i]]
            writer = csv.writer(csvFile)
            writer.writerow(row)
    csvFile.close()

    for i in range (len(Y_test[:, 0, 0, 0])):
        targMap = plt.figure()
        sns.heatmap(Y_test[i, :, :, 0])
        targMap.title("Target Map %s" %i)
        targMap.savefig("TargMap_%s.png" %i)

        predMap = plt.figure()
        sns.heatmap(pred[i, :, :, 0])
        predMap.title("Predicted Map %s" %i)
        predMap.savefig("PredMap_%s.png" %i)

########
# Main #
########

volumes, pulseMaps = ImportData()
mod, hist, testfMRI, testpMap = TPNet(volumes, pulseMaps)
predictions = mod.predict (testfMRI)
error(testfMRI, predictions)



